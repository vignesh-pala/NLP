{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CtsNLP_Ch5_countmatrix.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3dXg7C2OGDjHcnhDW0Yi/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vignesh-pala/NLP/blob/master/Ch5_6/CtsNLP_Ch5_countmatrix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWdgZg6N7bNy",
        "colab_type": "text"
      },
      "source": [
        "**Challenge 5** :  Assume you are looking to build a model to predict if the text you are seeing is an issue or informational message. For e.g. job completed is an informational message whereas job abended is an issue.  The objective is to predict the issue. \n",
        "\n",
        " \n",
        "\n",
        "The task is multi fold\n",
        "\n",
        "\n",
        "\n",
        "1.   Generate the label for each data point to see if its informational or an issue\n",
        "2.  Build a count based matrix for each issue which reflects the number of occurrence of each word in the text along with the label\n",
        "3. You can choose to restrict to a certain number of words based on your analysis\n",
        "4.You can choose to remove the STOPWORDS from each text \n",
        "5.The count based matrix that you build for the entire data set should be in a format such that it can be given as an input to any of the algorithm for training and testing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O0QZTBjihZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "c0f14786-59a6-4230-d586-d887da47dec5"
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "import pandas as pd\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import metrics\n",
        "\n",
        "from scipy.spatial import distance\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVjN2x9rjMj7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "94007046-786a-4674-d906-d255088d7a8d"
      },
      "source": [
        "df = pd.read_csv('/content/ticket_Data_labelled_input.csv',encoding='ISO-8859-1')\n",
        "df.head()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the job failed due to row count mismatch betwe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Job got failed due to name pipe error.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Job got failed due to duplicate issue.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Job got failed due to file unavailability.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Job got failed due to tdata connectivity issue.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  the job failed due to row count mismatch betwe...      0\n",
              "1             Job got failed due to name pipe error.      0\n",
              "2             Job got failed due to duplicate issue.      0\n",
              "3         Job got failed due to file unavailability.      0\n",
              "4    Job got failed due to tdata connectivity issue.      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsrMWHt54EO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = df['Sentence']\n",
        "#stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg9q9Zs7mfCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vect = CountVectorizer(stop_words ='english' )\n",
        "vector = count_vect.fit_transform(text)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIZf0oIHHX2t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "089e7f4d-9876-4db8-8132-9a31076b9bc3"
      },
      "source": [
        "print(count_vect.vocabulary_)\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'job': 320, 'failed': 245, 'row': 526, 'count': 147, 'mismatch': 392, 'source': 571, 'file': 252, 'ods': 416, 'table': 615, 'got': 268, 'pipe': 437, 'error': 224, 'duplicate': 208, 'issue': 312, 'unavailability': 664, 'tdata': 625, 'connectivity': 131, 'hadoop': 269, 'database': 162, 'named': 403, 'data': 160, 'log': 364, 'time': 638, 'executed': 234, 'completed': 117, 'successfully': 601, 'cancelled': 82, 'day': 168, 'records': 479, 'deleteing': 182, 'invalid': 308, 'collect': 106, 'stats': 582, 'killed': 331, 'hanged': 272, 'long': 366, 'manually': 383, 'format': 260, 'login': 365, 'null': 411, 'value': 691, 'running': 532, 'aborted': 12, 'tbload': 621, 'successfulll': 599, 'releasing': 493, 'process': 450, 'state': 581, 'failure': 246, 'query': 464, 'outage': 424, 'unailability': 663, 'abended': 10, 'connection': 129, 'low': 372, 'disk': 200, 'space': 573, 'started': 580, 'jobs': 322, 'values': 692, 'execution': 236, 'incorrect': 295, 'stream': 588, 'closure': 102, 'timeeout': 640, 'existence': 237, 'bad': 56, 'character': 91, 'timed': 639, 'connecitivity': 126, 'issuee': 313, 'skipped': 563, 'continued': 139, 'trigger': 657, 'production': 453, 'issues': 314, 'namepipe': 404, 'successful': 597, 'rerun': 508, 'tods': 648, 'missing': 393, 'leads': 338, 'update': 678, 'status': 583, 'changed': 89, 'marked': 386, 'success': 596, 'bee': 66, 'deleting': 183, 'dead': 172, 'lock': 360, 'resolved': 513, 'recieved': 477, 'target': 619, 'validation': 689, 'dba': 171, 'timeout': 641, 'spool': 574, 'db': 170, 'ran': 470, 'later': 336, 'connectivty': 132, 'released': 491, 'server': 556, 'getting': 265, 'extraction': 241, 'batch': 61, 'cancelling': 83, 'ambiguos': 32, 'active': 17, 'run': 530, 'validity': 690, 'reran': 506, 'sulting': 611, 'team': 627, 'successfull': 598, 'brj': 74, 'unlinked': 675, 'udated': 662, 'availability': 47, 'confirmed': 125, 'connecitvity': 127, 'theen': 634, 'td': 624, 'duplicates': 209, 'moving': 400, 'dupliacates': 206, 'rfc': 523, 'connectivitity': 130, 'exception': 229, 'ststs': 589, 'unavailbility': 669, 'updating': 680, 'updated': 679, 'clearing': 97, 'temp': 629, 'unique': 672, 'constraint': 135, 'violated': 693, 'dauplicate': 167, 'script': 549, 'contains': 137, 'unwanted': 676, 'definition': 176, 'runing': 531, 'occured': 413, 'scripts': 550, 'available': 48, 'moload': 396, 'release': 490, 'tables': 616, 'performance': 435, 'little': 354, 'slow': 566, 'large': 334, 'backlog': 53, 'covered': 148, 'cleared': 96, 'exection': 231, 'session': 558, 'blocked': 68, 'blocking': 69, 'queries': 463, 'today': 646, 'communication': 113, 'fixed': 256, 'restarted': 519, 'timestam': 642, 'correct': 142, 'stamp': 578, 'self': 552, 'deleted': 181, 'upgrade': 681, 'succesfully': 595, 'resolving': 514, 'event': 226, 'attribute': 44, 'record': 478, 'enviroment': 219, 'middle': 390, 'link': 352, 'conneection': 133, 'lost': 371, 'falied': 247, 'etq': 225, 'closed': 100, 'correctly': 145, 'archieve': 37, 'area': 38, 'piped': 438, 'runnng': 534, 'date': 165, 'corrected': 143, 'previous': 446, 'step': 585, 'scheduler': 544, 'ssis': 576, 'tool': 650, 'related': 489, 'crm': 153, 'oout': 418, 'erro': 223, 'aaraise': 8, 'wehave': 703, 'huge': 287, 'volume': 694, 'load': 357, 'console': 134, 'locking': 362, 'didn': 195, 'triggered': 658, 'backend': 51, 'room': 524, 'tmp': 644, 'reprocessed': 501, 'adding': 22, 'didnt': 196, 'audit': 45, 'entry': 218, 'numeric': 412, 'overflow': 425, 'held': 276, 'longer': 367, 'schedule': 542, 'discussion': 199, 'todays': 647, 'bw': 78, 'end': 216, 'received': 474, 'staging': 577, 'intimated': 307, 'entries': 217, 'wrong': 709, 'alert': 29, 'raised': 468, 'tns': 645, 'listener': 353, 'nextday': 410, 'removing': 496, 'resend': 510, 'processing': 452, 'days': 169, 'causing': 87, 'past': 431, 'delay': 178, 'week': 700, 'order': 422, 'avoid': 49, 'backlogs': 54, 'brite': 73, 'rerunning': 509, 'wrongly': 710, 'particular': 430, 'delayed': 179, 'completion': 122, 'start': 579, 'reexecuting': 486, 'teh': 628, 'parsing': 429, 'carried': 84, 'restart': 517, 'fix': 254, 'files': 253, 'schedulre': 546, 'late': 335, 'cm': 104, 'customer': 158, 'matching': 388, 'liasing': 350, 'kept': 328, 'hold': 280, 'jot': 325, 'sql': 575, 'present': 444, 'collecting': 108, 'fast': 248, 'effected': 213, 'complex': 123, 'immediately': 290, 'required': 505, 'address': 23, 'initial': 301, 'insert': 304, 'hours': 282, 'removed': 495, 'previos': 445, 'current': 156, 'mdl': 389, 'seperately': 554, 'manaully': 379, 'substitution': 591, 'parameter': 428, 'succssfully': 605, 'manual': 382, 'change': 88, 'rectify': 480, 'stuck': 590, 'occurred': 414, 'validataion': 688, 'properly': 456, 'inlast': 302, 'gludad': 267, 'sml': 568, 'schdelue': 540, 'news': 409, 'added': 21, 'lapsed': 333, 'contract': 140, 'patching': 432, 'previsouly': 447, 'triigered': 661, 'created': 151, 'management': 377, 'fail': 244, 'affceting': 28, 'ths': 635, 'maid': 374, 'qac': 461, 'services': 557, 'quotes': 466, 'execute': 233, 'incoorect': 294, 'datetime': 166, 'pulled': 460, 'sucessfully': 609, 'unzipping': 677, 'tbuild': 623, 'scuessfully': 551, 'dropped': 203, 'rexecuted': 522, 'sbi': 539, 'column': 110, 'incident': 292, 'beacuse': 65, 'longrunning': 368, 'dataa': 161, 'instance': 306, 'yesterday': 712, 'ems': 215, 'incorrectly': 296, 'queue': 465, 'action': 16, 'receiving': 475, 'rr11': 527, 'kb': 326, 'copied': 141, 'saa': 536, 'warnings': 697, 'increasing': 298, 'alerts': 30, 'arrival': 40, 'informed': 299, 'user': 684, 'kill': 330, 'high': 279, 'cpu': 150, 'usage': 682, 'requested': 504, 'triggering': 659, 'warning': 696, 'incidents': 293, 'input': 303, 'transfer': 651, 'sas': 537, 'path': 433, 'rr12': 528, 'users': 685, 'delete': 180, 'description': 189, 'place': 439, 'placing': 441, 'provided': 458, 'schedules': 545, 'unavailaility': 668, 'deadline': 173, 'box': 71, 'reexecuted': 485, 'reduced': 481, 'happened': 273, 'provide': 457, 'oraacle': 420, 'oracle': 421, 'unavailable': 665, 'backup': 55, 'placed': 440, 'isue': 316, 'trigerred': 655, 'dupllicate': 210, 'compelted': 114, 'weekend': 701, 'processed': 451, 'avaialble': 46, 'succefully': 593, 'scheduls': 547, 'batches': 63, 'enxt': 221, 'executing': 235, 'contacted': 136, 'field': 251, 'sucecssfully': 606, 'reference': 487, 'resoved': 515, 'adn': 27, 'fixing': 258, 'wass': 699, 'level': 341, 'backened': 52, 'usual': 687, 'able': 11, 'connect': 128, 'dependent': 187, 'breached': 72, 'completing': 121, 'creating': 152, 'new': 408, 'arm': 39, 'frond': 262, 'cmd': 105, 'locked': 361, 'moved': 399, 'archieval': 36, 'abend': 9, 'clocing': 98, 'succesful': 594, 'comfirmed': 111, 'loaded': 358, 'sp': 572, 'extra': 239, 'succcessfully': 592, 'free': 261, 'execueted': 232, 'wnash': 706, 'access': 13, 'arrived': 41, 'completeled': 119, 'changing': 90, 'hene': 278, 'canceelled': 80, 'loack': 355, 'called': 79, 'support': 613, 'closing': 101, 'runon': 535, 'sundays': 612, 'bandwidth': 57, 'tanle': 618, 'triggred': 660, 'maestro': 373, 'disconnected': 198, 'th': 632, 'stop': 587, 'permanent': 436, 'planned': 442, 'activity': 18, 'csi': 154, 'task': 620, 'csitask00001054': 155, 'events': 227, 'lh': 342, 'batched': 62, 'undergoing': 671, 'thsi': 636, 'switchedoff': 614, 'scheduled': 543, 'rsolved': 529, 'faield': 243, 'delated': 177, 'loacked': 356, 'relelased': 494, 'lcok': 337, 'duee': 204, 'fixeed': 257, 'completeed': 118, 'close': 99, 'successfulyy': 603, 'dupliactes': 207, 'collected': 107, 'jo': 319, 'complted': 124, 'duplciates': 205, 'runningthe': 533, 'main': 375, 'steps': 586, 'ignored': 289, 'reun': 520, 'actvitiy': 20, 'dont': 202, 'raise': 467, 'application': 34, 'warranty': 698, 'looking': 370, 'ffixed': 250, 'expired': 238, 'did': 194, 'complete': 116, 'checked': 92, 'need': 405, 'shcdule': 561, 'cpmp': 149, 'leted': 340, 'sent': 553, 'adhoc': 25, 'environment': 220, 'slef': 565, 'successfullly': 600, 'edw': 211, 'raising': 469, 'overrunning': 426, 'reached': 471, 'successully': 604, 'receving': 476, 'id': 288, 'excecuted': 228, 'handled': 270, 'based': 59, 'root': 525, 'assignement': 43, 'monthly': 398, 'needed': 406, 'chnage': 93, 'isuse': 317, 'completd': 115, 'managing': 378, 'ticket': 637, 'delted': 185, 'monday': 397, 'weekly': 702, 'isssue': 311, 'solved': 569, 'liaising': 347, 'dev': 191, 'lockout': 363, 'reesolved': 484, 'terminated': 631, 'scope': 548, 'correcting': 144, 'withsource': 705, 'disabled': 197, 'request': 503, 'hr': 285, 'decommissioned': 175, 'hang': 271, 'help': 277, 'went': 704, 'ot': 423, 'unknown': 673, 'backed': 50, '99': 7, 'using': 686, 'datafix': 163, 'manullay': 384, 'inserted': 305, 'working': 708, 'reerun': 483, 'reraun': 507, 'pending': 434, 'procedd': 448, 'minutes': 391, 'unavailaibilty': 667, 'housekeeping': 284, 'base': 58, '20': 3, '00': 0, '55': 6, 'bst': 76, 'admin': 26, 'liaisng': 348, 'development': 192, 'informing': 300, 'deadlines': 174, 'progressing': 455, 'slowly': 567, 'nad': 401, 'business': 77, 'liainsing': 345, 'taking': 617, 'exeception': 230, 'satging': 538, 'liaise': 346, 'continue': 138, 'isse': 310, 'cleansed': 94, 'fixe': 255, 'open': 419, 'hub': 286, 'gets': 264, '3days': 5, 'bi': 67, '15': 2, 'reboot': 472, 'unlink': 674, 'currently': 157, 'investigating': 309, 'jobfailed': 321, 'procedure': 449, 'mannaully': 380, 'reset': 511, 'restarte': 518, 'jon': 323, 'successfuly': 602, 'deployment': 188, 'house': 283, 'keeping': 327, 'progress': 454, 'addressed': 24, 'carry': 85, '0kb': 1, 'reprocess': 500, 'wapph005p01': 695, 'accessible': 14, 'sleep': 564, 'mannualy': 381, 'allocated': 31, 'beacon': 64, 'hdp': 275, 'catch': 86, 'canceled': 81, 'tomorrow': 649, 'jib': 318, 'transform': 653, 'erred': 222, 'releases': 492, 'liase': 349, 'brp': 75, 'sequentially': 555, 'unavailibilty': 670, 'corresponding': 146, 'parallel': 427, 'daily': 159, 'tried': 654, 'command': 112, 'line': 351, 'sucessful': 608, 'marking': 387, 'inbrj': 291, 'extractor': 242, 'having': 274, 'occuured': 415, 'acttioned': 19, 'accordingly': 15, 'replacing': 497, 'issus': 315, 'responding': 516, 'site': 562, 'liainsg': 344, 'providing': 459, 'suceessfully': 607, 'receive': 473, 'regular': 488, 'basis': 60, '21': 4, 'needs': 407, 'devteam': 193, 'set': 560, 'extracted': 240, 'resolve': 512, 'dependency': 186, 'applications': 35, 'laising': 332, 'redwood': 482, 'following': 259, 'liainsfg': 343, 'reprocssed': 502, 'feed': 249, 'used': 683, 'schedueler': 541, 'trigfered': 656, 'collects': 109, 'let': 339, 'qas': 462, 'tbloaded': 622, 'cluster': 103, 'manage': 376, 'effectiveness': 214, 'teradtaa': 630, 'ws': 711, 'look': 369, 'older': 417, 'sessions': 559, 'thanks': 633, 'nagapriya': 402, 'reporcessed': 498, 'unavailablitiy': 666, 'steam': 584, 'mlock': 395, 'edwprdt_tmp': 212, 'pointing': 443, 'timestamp': 643, 'deletion': 184, 'mloa': 394, 'dissue': 201, 'reurn': 521, 'manully': 385, 'reprcessed': 499, 'sorted': 570, 'completely': 120, 'bod': 70, 'clear': 95, 'ans': 33, 'ftp': 263, 'transferred': 652, 'asked': 42, 'details': 190, 'given': 266, 'tea': 626, 'increase': 297, 'work': 707, 'host': 281, 'key': 329, 'jopb': 324, 'sucessfun': 610, 'dataset': 164, 'locekd': 359}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEpytys_noy7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "5e209e1b-2962-4b40-8d59-8619a21d2a9e"
      },
      "source": [
        "# summarize encoded vector\n",
        "print(vector.shape)\n",
        "print(type(vector))\n",
        "print(vector.toarray()[0])"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9495, 713)\n",
            "<class 'scipy.sparse.csr.csr_matrix'>\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-c-QOmGM28e",
        "colab_type": "text"
      },
      "source": [
        "**Challenge 6:**\n",
        "This is an extension to the Challenge 5 .  Assume you are looking to build a model to predict if the text you are seeing is an issue or informational message. For e.g. job completed is an informational message whereas job abended is an issue.  The objective is to predict the issue.\n",
        "\n",
        " \n",
        "\n",
        "Build a TF-IDF based matrix along with the label.\n",
        "\n",
        "Explore giving that input into a logistic regression to predict if the given text is an issue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZvdZRV8ObcX",
        "colab_type": "text"
      },
      "source": [
        "Split Train, Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPCzq01n764K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df['Sentence']\n",
        "y = df['Label']\n",
        "\n",
        "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-dXqDRcPaog",
        "colab_type": "text"
      },
      "source": [
        "**Build pipeline to vectorize data, train and fit model**\n",
        "\n",
        "**Lets try CountVectorizer first**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "381BvlM1Uq6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Naive Bayes:\n",
        "txt_clf_nb = Pipeline([('tfidf', CountVectorizer()), \n",
        "                       ('clf', MultinomialNB())])\n",
        "\n",
        "#LinearSVC:\n",
        "txt_clf_lsvc = Pipeline([('tfidf', CountVectorizer()),\n",
        "                         ('clf', LinearSVC())])"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7NLcGEnR2kB",
        "colab_type": "text"
      },
      "source": [
        "Naive Bayes Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9L9A015Raxc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "f227276c-f1c3-4921-9fff-93b8fdec1e1c"
      },
      "source": [
        "txt_clf_nb.fit(X_train, y_train)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjzlOGpnRxBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = txt_clf_nb.predict(X_test)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic7_OdMfO3hg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "a44ecfb2-8043-4f1c-ec9d-201fb150375e"
      },
      "source": [
        "print(metrics.confusion_matrix(y_test, pred))\n",
        "\n",
        "# Print the overall accuracy\n",
        "print(\"Accuracy of Naive Bayes with CountVectorizer : \",metrics.accuracy_score(y_test,pred))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 847   23]\n",
            " [ 181 2083]]\n",
            "Accuracy of Naive Bayes with CountVectorizer :  0.9349074664964901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efh-nBytTVuu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "57569baa-d9e1-41b0-ea28-63cadd3baf10"
      },
      "source": [
        "print(metrics.classification_report(y_test, pred))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.97      0.89       870\n",
            "           1       0.99      0.92      0.95      2264\n",
            "\n",
            "    accuracy                           0.93      3134\n",
            "   macro avg       0.91      0.95      0.92      3134\n",
            "weighted avg       0.94      0.93      0.94      3134\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGTEKHT_Tunp",
        "colab_type": "text"
      },
      "source": [
        "LinearSVC pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GRXoqRFT22A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "b6eba4d7-23d0-4b90-b311-68979eca0203"
      },
      "source": [
        "txt_clf_lsvc.fit(X_train, y_train)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('clf',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxuTLKxkUA_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = txt_clf_lsvc.predict(X_test)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXJ4xGzUUFps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "d841c85d-775d-43e1-811f-7eac3bf204d2"
      },
      "source": [
        "print(metrics.confusion_matrix(y_test, pred))\n",
        "\n",
        "# Print the overall accuracy\n",
        "print(\"Accuracy of Linear svc with CountVectorizer : \",metrics.accuracy_score(y_test,pred))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 859   11]\n",
            " [   1 2263]]\n",
            "Accuracy of Linear svc with CountVectorizer :  0.99617102744097\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC4O_w8LURWh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "fca2b007-2d3e-4730-f9bc-b5dfa1161d02"
      },
      "source": [
        "print(metrics.classification_report(y_test, pred))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       870\n",
            "           1       1.00      1.00      1.00      2264\n",
            "\n",
            "    accuracy                           1.00      3134\n",
            "   macro avg       1.00      0.99      1.00      3134\n",
            "weighted avg       1.00      1.00      1.00      3134\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfB0LNqbXIUx",
        "colab_type": "text"
      },
      "source": [
        "**Summary of CountVectorizer**\n",
        "\n",
        "\n",
        "*   Accuracy of Naive Bayes with CountVectorizer :  **0.9349074664964901**\n",
        "*   Accuracy of Linear svc with CountVectorizer   :  **0.99617102744097**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6bMqj2OUO_q",
        "colab_type": "text"
      },
      "source": [
        "**Lets try TfidfVectorizer first**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTS7mb6RP9Sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Naive Bayes:\n",
        "txt_clf_nb = Pipeline([('tfidf', TfidfVectorizer()), \n",
        "                       ('clf', MultinomialNB())])\n",
        "\n",
        "#LinearSVC:\n",
        "txt_clf_lsvc = Pipeline([('tfidf', TfidfVectorizer()),\n",
        "                         ('clf', LinearSVC())])"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsakKl08YYJd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "d935d0e0-883a-420f-fd99-3ca9c2435fab"
      },
      "source": [
        "txt_clf_nb.fit(X_train, y_train)\n",
        "pred = txt_clf_nb.predict(X_test)\n",
        "print(metrics.confusion_matrix(y_test, pred))\n",
        "\n",
        "# Print the overall accuracy\n",
        "print(\"Accuracy of Naive Bayes with TfidfVectorizer : \",metrics.accuracy_score(y_test,pred))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 835   35]\n",
            " [ 111 2153]]\n",
            "Accuracy of Naive Bayes with TfidfVectorizer :  0.9534141671984684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcKpdptqYbul",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "4ea85240-596e-484c-9115-1d91eb0e7cc4"
      },
      "source": [
        "txt_clf_lsvc.fit(X_train, y_train)\n",
        "pred = txt_clf_lsvc.predict(X_test)\n",
        "print(metrics.confusion_matrix(y_test, pred))\n",
        "\n",
        "# Print the overall accuracy\n",
        "print(\"Accuracy of Naive Bayes with TfidfVectorizer : \",metrics.accuracy_score(y_test,pred))"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 861    9]\n",
            " [   2 2262]]\n",
            "Accuracy of Naive Bayes with TfidfVectorizer :  0.9964901084875558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOHt0zWwY4gB",
        "colab_type": "text"
      },
      "source": [
        "**Summary of CountVectorizer**\n",
        "\n",
        "\n",
        "*   Accuracy of Naive Bayes with TfidfVectorizer :  **0.9534141671984684**\n",
        "*   Accuracy of Naive Bayes with TfidfVectorizer :  **0.9964901084875558**"
      ]
    }
  ]
}