{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Ch14_TextGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1YerW063XwrauC5udkROu6TdJsKO8ang8",
      "authorship_tag": "ABX9TyOldGTORBInA3dwD4YnE3i4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vignesh-pala/NLP/blob/master/NLP_Ch14_TextGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI03gZ9PnrSt",
        "colab_type": "text"
      },
      "source": [
        "**Challenge 14 (NLP with Keras-TF2)**\n",
        "\n",
        " \n",
        "\n",
        "Learn how to generate text using LSTM and use it with your favorite ebook to generate some meaningful sentences.\n",
        "\n",
        "https://www.kaggle.com/shivamb/beginners-guide-to-text-generation-using-lstms\n",
        "\n",
        " \n",
        "\n",
        "You can use Google Colab for the actual coding and submit the link in this yammer thread.....\n",
        "\n",
        "-----------------End------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F134EcbMQAFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU\n",
        "\n",
        "# Loss function\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUKV389RQ6nZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_file = '/content/drive/My Drive/Colab Notebooks/TextFiles/Jungle_Book.txt'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HS6t9gpRaUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = open(path_to_file,'r').read()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd5RNiF-SR80",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "44c299df-9f7e-48a2-a333-112aa8955278"
      },
      "source": [
        "print(text[:1000])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿It was seven o’clock of a very warm evening in the Seeonee hills when\n",
            "Father Wolf woke up from his day’s rest, scratched himself, yawned, and\n",
            "spread out his paws one after the other to get rid of the sleepy feeling\n",
            "in their tips. Mother Wolf lay with her big gray nose dropped across her\n",
            "four tumbling, squealing cubs, and the moon shone into the mouth of the\n",
            "cave where they all lived. “Augrh!” said Father Wolf. “It is time to\n",
            "hunt again.” He was going to spring down hill when a little shadow with\n",
            "a bushy tail crossed the threshold and whined: “Good luck go with you, O\n",
            "Chief of the Wolves. And good luck and strong white teeth go with noble\n",
            "children that they may never forget the hungry in this world.”\n",
            "\n",
            "It was the jackal--Tabaqui, the Dish-licker--and the wolves of India\n",
            "despise Tabaqui because he runs about making mischief, and telling\n",
            "tales, and eating rags and pieces of leather from the village\n",
            "rubbish-heaps. But they are afraid of him too, because Tabaqui, more\n",
            "than anyone else in th\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip0OCk9sUepS",
        "colab_type": "text"
      },
      "source": [
        "Get Unique chars"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqW2nDGVUakw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "805324a9-fa91-490b-dcb2-907c3972c12e"
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "print(vocab)\n",
        "len(vocab)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n', ' ', '!', '$', '%', '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '‘', '’', '“', '”', '\\ufeff']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iW79fxuUu6o",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-CfuRNIUpaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_to_ind = {u:i for i,u in  enumerate(vocab)}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ41HVqHU35x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a3b71d39-65a7-4b62-ea59-95e6858956c1"
      },
      "source": [
        "print(char_to_ind)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '%': 4, '(': 5, ')': 6, '*': 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, ';': 23, '?': 24, '@': 25, 'A': 26, 'B': 27, 'C': 28, 'D': 29, 'E': 30, 'F': 31, 'G': 32, 'H': 33, 'I': 34, 'J': 35, 'K': 36, 'L': 37, 'M': 38, 'N': 39, 'O': 40, 'P': 41, 'Q': 42, 'R': 43, 'S': 44, 'T': 45, 'U': 46, 'V': 47, 'W': 48, 'X': 49, 'Y': 50, 'Z': 51, '[': 52, ']': 53, '`': 54, 'a': 55, 'b': 56, 'c': 57, 'd': 58, 'e': 59, 'f': 60, 'g': 61, 'h': 62, 'i': 63, 'j': 64, 'k': 65, 'l': 66, 'm': 67, 'n': 68, 'o': 69, 'p': 70, 'q': 71, 'r': 72, 's': 73, 't': 74, 'u': 75, 'v': 76, 'w': 77, 'x': 78, 'y': 79, 'z': 80, '‘': 81, '’': 82, '“': 83, '”': 84, '\\ufeff': 85}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXbwxdhSUz4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind_to_char = np.array(vocab)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95WRJ1u9VNH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "28f4cca8-d071-447d-ba11-d9024cb45679"
      },
      "source": [
        "ind_to_char"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\n', ' ', '!', '$', '%', '(', ')', '*', ',', '-', '.', '/', '0',\n",
              "       '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@',\n",
              "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
              "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
              "       '[', ']', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j',\n",
              "       'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w',\n",
              "       'x', 'y', 'z', '‘', '’', '“', '”', '\\ufeff'], dtype='<U1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa5M_30WVOot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d0d8e164-59a6-4e3a-db4c-df9b48f09cf1"
      },
      "source": [
        "ind_to_char[30]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'E'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_fh-R2aVuSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_text = np.array([char_to_ind[c] for c in text])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_PJS3f_UX1L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2dad23bf-13a6-4fb3-e86b-a2fc7395553d"
      },
      "source": [
        "print(encoded_text)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[85 34 74 ... 73 10  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SbTFbaQWb5M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9b0d330a-aa41-4e3f-cfcf-7b753845ab6d"
      },
      "source": [
        "sample = text[:20]\n",
        "sample"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ufeffIt was seven o’cloc'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iskGoQgVWkWI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2b014fb5-c1fb-4428-bc36-cec00398f73c"
      },
      "source": [
        "encoded_text[:20]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([85, 34, 74,  1, 77, 55, 73,  1, 73, 59, 76, 59, 68,  1, 69, 82, 57,\n",
              "       66, 69, 57])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUnDcadzWTRn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bfc9d360-62f3-430c-c7d9-5a1e4d4f9fc9"
      },
      "source": [
        "encoded_text.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(291664,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IURcW5EcW_bE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "7da00645-e549-468c-8a0b-7b8f3cd05b1f"
      },
      "source": [
        "print(text[:1000])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿It was seven o’clock of a very warm evening in the Seeonee hills when\n",
            "Father Wolf woke up from his day’s rest, scratched himself, yawned, and\n",
            "spread out his paws one after the other to get rid of the sleepy feeling\n",
            "in their tips. Mother Wolf lay with her big gray nose dropped across her\n",
            "four tumbling, squealing cubs, and the moon shone into the mouth of the\n",
            "cave where they all lived. “Augrh!” said Father Wolf. “It is time to\n",
            "hunt again.” He was going to spring down hill when a little shadow with\n",
            "a bushy tail crossed the threshold and whined: “Good luck go with you, O\n",
            "Chief of the Wolves. And good luck and strong white teeth go with noble\n",
            "children that they may never forget the hungry in this world.”\n",
            "\n",
            "It was the jackal--Tabaqui, the Dish-licker--and the wolves of India\n",
            "despise Tabaqui because he runs about making mischief, and telling\n",
            "tales, and eating rags and pieces of leather from the village\n",
            "rubbish-heaps. But they are afraid of him too, because Tabaqui, more\n",
            "than anyone else in th\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8YBaJ-NUPzg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7dfa797-94fe-466c-ea9b-6f2901b14895"
      },
      "source": [
        "len('﻿It was seven o’clock of a very warm evening in the Seeonee hills when')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05BUOyniUNSO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11b7c656-0456-4b4a-8fe7-b73245ed1bca"
      },
      "source": [
        "len(''' \n",
        "It was seven o’clock of a very warm evening in the Seeonee hills when\n",
        "Father Wolf woke up from his day’s rest, scratched himself, yawned, and\n",
        "spread out his paws one after the other to get rid of the sleepy feeling\n",
        "''')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "217"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx9VuqXSYLn9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3683653-7880-40b7-a4e7-b9495974f5da"
      },
      "source": [
        "seq_len = 100\n",
        "total_num_seq =  len(text)//(seq_len + 1)\n",
        "total_num_seq"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2887"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd23V9p0Yllj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "412ccdfe-4ee0-4889-88e2-346e946fe79b"
      },
      "source": [
        "  # Create Training Sequences\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
        "\n",
        "for i in char_dataset.take(500):\n",
        "     print(ind_to_char[i.numpy()])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿\n",
            "I\n",
            "t\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "s\n",
            "e\n",
            "v\n",
            "e\n",
            "n\n",
            " \n",
            "o\n",
            "’\n",
            "c\n",
            "l\n",
            "o\n",
            "c\n",
            "k\n",
            " \n",
            "o\n",
            "f\n",
            " \n",
            "a\n",
            " \n",
            "v\n",
            "e\n",
            "r\n",
            "y\n",
            " \n",
            "w\n",
            "a\n",
            "r\n",
            "m\n",
            " \n",
            "e\n",
            "v\n",
            "e\n",
            "n\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "i\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "S\n",
            "e\n",
            "e\n",
            "o\n",
            "n\n",
            "e\n",
            "e\n",
            " \n",
            "h\n",
            "i\n",
            "l\n",
            "l\n",
            "s\n",
            " \n",
            "w\n",
            "h\n",
            "e\n",
            "n\n",
            "\n",
            "\n",
            "F\n",
            "a\n",
            "t\n",
            "h\n",
            "e\n",
            "r\n",
            " \n",
            "W\n",
            "o\n",
            "l\n",
            "f\n",
            " \n",
            "w\n",
            "o\n",
            "k\n",
            "e\n",
            " \n",
            "u\n",
            "p\n",
            " \n",
            "f\n",
            "r\n",
            "o\n",
            "m\n",
            " \n",
            "h\n",
            "i\n",
            "s\n",
            " \n",
            "d\n",
            "a\n",
            "y\n",
            "’\n",
            "s\n",
            " \n",
            "r\n",
            "e\n",
            "s\n",
            "t\n",
            ",\n",
            " \n",
            "s\n",
            "c\n",
            "r\n",
            "a\n",
            "t\n",
            "c\n",
            "h\n",
            "e\n",
            "d\n",
            " \n",
            "h\n",
            "i\n",
            "m\n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            ",\n",
            " \n",
            "y\n",
            "a\n",
            "w\n",
            "n\n",
            "e\n",
            "d\n",
            ",\n",
            " \n",
            "a\n",
            "n\n",
            "d\n",
            "\n",
            "\n",
            "s\n",
            "p\n",
            "r\n",
            "e\n",
            "a\n",
            "d\n",
            " \n",
            "o\n",
            "u\n",
            "t\n",
            " \n",
            "h\n",
            "i\n",
            "s\n",
            " \n",
            "p\n",
            "a\n",
            "w\n",
            "s\n",
            " \n",
            "o\n",
            "n\n",
            "e\n",
            " \n",
            "a\n",
            "f\n",
            "t\n",
            "e\n",
            "r\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "o\n",
            "t\n",
            "h\n",
            "e\n",
            "r\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "g\n",
            "e\n",
            "t\n",
            " \n",
            "r\n",
            "i\n",
            "d\n",
            " \n",
            "o\n",
            "f\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "s\n",
            "l\n",
            "e\n",
            "e\n",
            "p\n",
            "y\n",
            " \n",
            "f\n",
            "e\n",
            "e\n",
            "l\n",
            "i\n",
            "n\n",
            "g\n",
            "\n",
            "\n",
            "i\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "i\n",
            "r\n",
            " \n",
            "t\n",
            "i\n",
            "p\n",
            "s\n",
            ".\n",
            " \n",
            "M\n",
            "o\n",
            "t\n",
            "h\n",
            "e\n",
            "r\n",
            " \n",
            "W\n",
            "o\n",
            "l\n",
            "f\n",
            " \n",
            "l\n",
            "a\n",
            "y\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "h\n",
            "e\n",
            "r\n",
            " \n",
            "b\n",
            "i\n",
            "g\n",
            " \n",
            "g\n",
            "r\n",
            "a\n",
            "y\n",
            " \n",
            "n\n",
            "o\n",
            "s\n",
            "e\n",
            " \n",
            "d\n",
            "r\n",
            "o\n",
            "p\n",
            "p\n",
            "e\n",
            "d\n",
            " \n",
            "a\n",
            "c\n",
            "r\n",
            "o\n",
            "s\n",
            "s\n",
            " \n",
            "h\n",
            "e\n",
            "r\n",
            "\n",
            "\n",
            "f\n",
            "o\n",
            "u\n",
            "r\n",
            " \n",
            "t\n",
            "u\n",
            "m\n",
            "b\n",
            "l\n",
            "i\n",
            "n\n",
            "g\n",
            ",\n",
            " \n",
            "s\n",
            "q\n",
            "u\n",
            "e\n",
            "a\n",
            "l\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "c\n",
            "u\n",
            "b\n",
            "s\n",
            ",\n",
            " \n",
            "a\n",
            "n\n",
            "d\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "m\n",
            "o\n",
            "o\n",
            "n\n",
            " \n",
            "s\n",
            "h\n",
            "o\n",
            "n\n",
            "e\n",
            " \n",
            "i\n",
            "n\n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "m\n",
            "o\n",
            "u\n",
            "t\n",
            "h\n",
            " \n",
            "o\n",
            "f\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "\n",
            "\n",
            "c\n",
            "a\n",
            "v\n",
            "e\n",
            " \n",
            "w\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "y\n",
            " \n",
            "a\n",
            "l\n",
            "l\n",
            " \n",
            "l\n",
            "i\n",
            "v\n",
            "e\n",
            "d\n",
            ".\n",
            " \n",
            "“\n",
            "A\n",
            "u\n",
            "g\n",
            "r\n",
            "h\n",
            "!\n",
            "”\n",
            " \n",
            "s\n",
            "a\n",
            "i\n",
            "d\n",
            " \n",
            "F\n",
            "a\n",
            "t\n",
            "h\n",
            "e\n",
            "r\n",
            " \n",
            "W\n",
            "o\n",
            "l\n",
            "f\n",
            ".\n",
            " \n",
            "“\n",
            "I\n",
            "t\n",
            " \n",
            "i\n",
            "s\n",
            " \n",
            "t\n",
            "i\n",
            "m\n",
            "e\n",
            " \n",
            "t\n",
            "o\n",
            "\n",
            "\n",
            "h\n",
            "u\n",
            "n\n",
            "t\n",
            " \n",
            "a\n",
            "g\n",
            "a\n",
            "i\n",
            "n\n",
            ".\n",
            "”\n",
            " \n",
            "H\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "g\n",
            "o\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "s\n",
            "p\n",
            "r\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "d\n",
            "o\n",
            "w\n",
            "n\n",
            " \n",
            "h\n",
            "i\n",
            "l\n",
            "l\n",
            " \n",
            "w\n",
            "h\n",
            "e\n",
            "n\n",
            " \n",
            "a\n",
            " \n",
            "l\n",
            "i\n",
            "t\n",
            "t\n",
            "l\n",
            "e\n",
            " \n",
            "s\n",
            "h\n",
            "a\n",
            "d\n",
            "o\n",
            "w\n",
            " \n",
            "w\n",
            "i\n",
            "t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf58lZS2bBfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idE7Nm-bYZTk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55ea0ba4-0975-4f31-fefd-f7c9d141edf3"
      },
      "source": [
        "sequences"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: (101,), types: tf.int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1ur8aLNbN6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_seq_targets(seq):\n",
        "    input_txt = seq[:-1]\n",
        "    target_txt = seq[1:]\n",
        "    return input_txt, target_txt"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y5VelLVbXK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = sequences.map(create_seq_targets)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8GFLZtRUHC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "980c74a5-221a-4a25-a2f9-259dba41f85e"
      },
      "source": [
        "for input_txt, target_txt in  dataset.take(1):\n",
        "    print(input_txt.numpy())\n",
        "    print(''.join(ind_to_char[input_txt.numpy()]))\n",
        "    print('\\n')\n",
        "    print(target_txt.numpy())\n",
        "    # There is an extra whitespace!\n",
        "    print(''.join(ind_to_char[target_txt.numpy()]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[85 34 74  1 77 55 73  1 73 59 76 59 68  1 69 82 57 66 69 57 65  1 69 60\n",
            "  1 55  1 76 59 72 79  1 77 55 72 67  1 59 76 59 68 63 68 61  1 63 68  1\n",
            " 74 62 59  1 44 59 59 69 68 59 59  1 62 63 66 66 73  1 77 62 59 68  0 31\n",
            " 55 74 62 59 72  1 48 69 66 60  1 77 69 65 59  1 75 70  1 60 72 69 67  1\n",
            " 62 63 73  1]\n",
            "﻿It was seven o’clock of a very warm evening in the Seeonee hills when\n",
            "Father Wolf woke up from his \n",
            "\n",
            "\n",
            "[34 74  1 77 55 73  1 73 59 76 59 68  1 69 82 57 66 69 57 65  1 69 60  1\n",
            " 55  1 76 59 72 79  1 77 55 72 67  1 59 76 59 68 63 68 61  1 63 68  1 74\n",
            " 62 59  1 44 59 59 69 68 59 59  1 62 63 66 66 73  1 77 62 59 68  0 31 55\n",
            " 74 62 59 72  1 48 69 66 60  1 77 69 65 59  1 75 70  1 60 72 69 67  1 62\n",
            " 63 73  1 58]\n",
            "It was seven o’clock of a very warm evening in the Seeonee hills when\n",
            "Father Wolf woke up from his d\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcqtlUlxbuaB",
        "colab_type": "text"
      },
      "source": [
        "Generating training batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQr3m2clTeRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batch size\n",
        "batch_size = 128\n",
        "\n",
        "# Buffer size to shuffle the dataset so it doesn't attempt to shuffle\n",
        "# the entire sequence in memory. Instead, it maintains a buffer in which it shuffles elements\n",
        "buffer_size = 10000\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAbFihgHbwCB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ff4ac09-cd07-48df-fd42-b1b1836cb095"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((128, 100), (128, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U92E1xLP_3-m",
        "colab_type": "text"
      },
      "source": [
        "Create the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01mATHGc_tzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embed_dim = 64\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_neurons = 1026"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2c_LHwLBNf_",
        "colab_type": "text"
      },
      "source": [
        "Creating the function, just to set the \"from_logits=True\", as it cant be done when its called in the model.compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku-rEW02Agj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sparse_cat_loss(y_true,y_pred):\n",
        "  return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01EAV3VBBZC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embed_dim,batch_input_shape=[batch_size, None]))\n",
        "    model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
        "    # Final Dense Layer to Predict\n",
        "    model.add(Dense(vocab_size))\n",
        "    model.compile(optimizer='adam', loss=sparse_cat_loss) \n",
        "    return model"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CGKBk4oBcHZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "1b9cda57-0451-4750-d31a-dc6498c01ac4"
      },
      "source": [
        "model = create_model(\n",
        "  vocab_size = vocab_size,\n",
        "  embed_dim=embed_dim,\n",
        "  rnn_neurons=rnn_neurons,\n",
        "  batch_size=batch_size)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (128, None, 64)           5504      \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (128, None, 1026)         3361176   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (128, None, 86)           88322     \n",
            "=================================================================\n",
            "Total params: 3,455,002\n",
            "Trainable params: 3,455,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sKkWziZB5u_",
        "colab_type": "text"
      },
      "source": [
        "Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_oL28kxB6ym",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4cdd5852-cde9-45cc-badc-e0e1d70ddb6d"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "\n",
        "  # Predict off some random batch\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "\n",
        "  # Display the dimensions of the predictions\n",
        "  print(example_batch_predictions.shape, \" <=== (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 100, 86)  <=== (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmYkmaaKCNo-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "47f59704-4ece-4f75-d154-0547a5e820c7"
      },
      "source": [
        "example_batch_predictions"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 100, 86), dtype=float32, numpy=\n",
              "array([[[ 2.8023538e-03,  6.2504743e-04, -4.5671654e-03, ...,\n",
              "          8.8604381e-03, -4.6302862e-03,  7.2382006e-04],\n",
              "        [ 1.4996742e-03,  1.7696379e-04, -2.4503912e-03, ...,\n",
              "          9.0468135e-03, -1.0047652e-02,  7.1900659e-03],\n",
              "        [ 3.6090356e-03, -4.0994529e-03,  1.3138730e-03, ...,\n",
              "          1.9106388e-04, -6.9942265e-03,  6.9705201e-03],\n",
              "        ...,\n",
              "        [ 7.7414261e-03,  3.4189899e-04, -8.2666110e-03, ...,\n",
              "         -6.8813367e-03, -1.1341625e-02,  6.1693490e-03],\n",
              "        [ 6.4810859e-03, -1.6488928e-03, -1.0044958e-03, ...,\n",
              "         -8.7335156e-03, -7.4498975e-03,  4.8984191e-03],\n",
              "        [ 1.2459241e-02,  3.7348983e-03,  4.6436801e-03, ...,\n",
              "         -1.3962424e-02, -1.4315343e-03,  4.4790567e-03]],\n",
              "\n",
              "       [[ 5.2096825e-03,  1.7620837e-03, -5.0730137e-03, ...,\n",
              "         -6.0555032e-03, -4.9323016e-03,  2.1271913e-03],\n",
              "        [ 4.8215119e-03, -5.0161383e-03, -1.0911295e-03, ...,\n",
              "          1.2685149e-04, -2.2520698e-03, -2.3145692e-03],\n",
              "        [ 5.0307172e-03, -4.0297327e-03,  4.3970481e-03, ...,\n",
              "         -4.6710712e-03, -1.4551602e-03,  3.5948871e-04],\n",
              "        ...,\n",
              "        [ 6.4845555e-03, -2.2276044e-03,  3.6070263e-04, ...,\n",
              "         -5.1607518e-03, -3.5929787e-03,  4.2215483e-03],\n",
              "        [-4.4388580e-03, -1.8185044e-03, -2.3779930e-03, ...,\n",
              "          1.3873798e-03, -2.4741021e-04, -1.8085720e-03],\n",
              "        [-1.1635987e-02,  3.5078702e-03, -7.4186819e-03, ...,\n",
              "         -1.1776364e-03,  1.4706581e-03,  5.5996294e-04]],\n",
              "\n",
              "       [[-1.0526016e-02,  4.4611553e-03, -5.2868994e-03, ...,\n",
              "         -1.8742838e-03,  1.5291765e-03,  2.4234559e-03],\n",
              "        [-2.3113197e-04,  5.8822911e-03, -8.0140289e-03, ...,\n",
              "         -6.5461751e-03, -4.3183491e-03,  2.6161708e-03],\n",
              "        [-5.0674891e-04,  2.2928468e-03, -5.9935022e-03, ...,\n",
              "         -4.9104951e-03,  1.1193231e-03,  8.3980188e-03],\n",
              "        ...,\n",
              "        [ 1.5446689e-03,  2.4888979e-03, -3.0025195e-03, ...,\n",
              "         -9.1141323e-03, -7.5071189e-03,  5.9273122e-03],\n",
              "        [ 1.7762815e-03,  1.6856570e-03,  7.3977932e-04, ...,\n",
              "         -1.0767070e-02, -1.4102670e-03, -1.6086752e-04],\n",
              "        [ 3.4955593e-03,  6.8026979e-04, -3.9808606e-03, ...,\n",
              "          4.0966817e-03, -4.7435034e-03,  1.1631782e-05]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 3.0940033e-03, -1.9944711e-03,  3.0227469e-03, ...,\n",
              "         -5.0262418e-03, -1.7607133e-03,  2.6847464e-03],\n",
              "        [ 5.8434642e-04,  4.7731800e-03, -1.9435681e-03, ...,\n",
              "         -2.8905983e-03, -2.6727121e-03,  2.1353371e-03],\n",
              "        [ 6.2182466e-03,  3.5759653e-03, -5.6702392e-03, ...,\n",
              "         -8.7223137e-03, -5.1993276e-03,  3.8515243e-03],\n",
              "        ...,\n",
              "        [ 9.1414088e-03,  1.0958235e-03,  7.7896602e-03, ...,\n",
              "         -1.0343944e-02,  5.1547387e-03, -1.2154884e-03],\n",
              "        [ 9.4593586e-03,  3.3679693e-03,  7.9234447e-03, ...,\n",
              "         -9.9767260e-03,  1.3941475e-03,  5.0850254e-03],\n",
              "        [ 8.7248394e-03,  3.4535871e-04,  8.2735373e-03, ...,\n",
              "         -1.1577553e-02, -6.5041165e-04,  5.1149060e-03]],\n",
              "\n",
              "       [[ 5.4197968e-03, -8.9181568e-03, -1.5307923e-03, ...,\n",
              "         -9.1670913e-04,  1.4295015e-03, -2.4663308e-04],\n",
              "        [-7.3280381e-03, -8.5554802e-04, -5.3831250e-03, ...,\n",
              "         -1.9283957e-03,  2.9794120e-03,  2.1755535e-03],\n",
              "        [-1.3260710e-03, -4.9063736e-03, -1.5557002e-03, ...,\n",
              "          2.9431826e-03,  1.8191403e-03, -2.9409749e-03],\n",
              "        ...,\n",
              "        [ 4.0738280e-03,  4.6645352e-03,  5.6860647e-03, ...,\n",
              "         -2.9470010e-03, -5.5953255e-03,  5.9080450e-03],\n",
              "        [ 3.0064150e-03,  4.3439100e-04,  1.9834696e-03, ...,\n",
              "         -2.5791586e-03,  7.8410207e-04,  9.4242217e-03],\n",
              "        [ 1.5037761e-03, -7.5228396e-05,  1.6816446e-03, ...,\n",
              "          3.2375273e-03, -8.0092009e-03,  1.0347033e-02]],\n",
              "\n",
              "       [[-2.2644605e-03, -3.1187874e-03, -4.0075448e-03, ...,\n",
              "         -3.1228443e-03,  2.6108944e-03,  5.3115594e-03],\n",
              "        [-2.8874644e-03, -3.3465149e-03, -4.6654558e-03, ...,\n",
              "         -1.0740445e-03,  3.0069272e-03,  8.4691402e-03],\n",
              "        [-3.8217299e-04, -4.2838906e-04,  2.5108771e-04, ...,\n",
              "         -4.9394006e-03,  4.6164198e-03,  1.9212284e-03],\n",
              "        ...,\n",
              "        [-7.4487994e-03, -1.9955286e-03, -1.8890345e-03, ...,\n",
              "          1.2066965e-03,  4.9930578e-03, -9.0785173e-04],\n",
              "        [ 5.3618086e-04, -3.7288139e-04,  5.1508578e-03, ...,\n",
              "         -2.7068940e-03,  2.7545430e-03, -7.5259469e-03],\n",
              "        [ 3.1793301e-03, -6.5155816e-04,  6.2780408e-03, ...,\n",
              "         -6.8772547e-03, -3.6326190e-04, -2.2099118e-04]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQBRlsSXBxg7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "79365a55-fb25-4594-b91e-70b1b8780d6e"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100, 1), dtype=int64, numpy=\n",
              "array([[15],\n",
              "       [54],\n",
              "       [38],\n",
              "       [ 4],\n",
              "       [50],\n",
              "       [32],\n",
              "       [30],\n",
              "       [10],\n",
              "       [59],\n",
              "       [43],\n",
              "       [85],\n",
              "       [10],\n",
              "       [50],\n",
              "       [85],\n",
              "       [10],\n",
              "       [78],\n",
              "       [15],\n",
              "       [55],\n",
              "       [30],\n",
              "       [19],\n",
              "       [38],\n",
              "       [54],\n",
              "       [70],\n",
              "       [79],\n",
              "       [55],\n",
              "       [ 7],\n",
              "       [56],\n",
              "       [11],\n",
              "       [37],\n",
              "       [13],\n",
              "       [22],\n",
              "       [74],\n",
              "       [77],\n",
              "       [24],\n",
              "       [15],\n",
              "       [ 8],\n",
              "       [53],\n",
              "       [21],\n",
              "       [40],\n",
              "       [53],\n",
              "       [41],\n",
              "       [ 8],\n",
              "       [61],\n",
              "       [67],\n",
              "       [67],\n",
              "       [78],\n",
              "       [69],\n",
              "       [81],\n",
              "       [13],\n",
              "       [55],\n",
              "       [68],\n",
              "       [44],\n",
              "       [85],\n",
              "       [76],\n",
              "       [20],\n",
              "       [35],\n",
              "       [77],\n",
              "       [ 2],\n",
              "       [80],\n",
              "       [69],\n",
              "       [42],\n",
              "       [77],\n",
              "       [75],\n",
              "       [80],\n",
              "       [50],\n",
              "       [39],\n",
              "       [ 4],\n",
              "       [12],\n",
              "       [52],\n",
              "       [64],\n",
              "       [82],\n",
              "       [ 2],\n",
              "       [58],\n",
              "       [66],\n",
              "       [39],\n",
              "       [85],\n",
              "       [84],\n",
              "       [23],\n",
              "       [10],\n",
              "       [66],\n",
              "       [21],\n",
              "       [65],\n",
              "       [36],\n",
              "       [26],\n",
              "       [85],\n",
              "       [16],\n",
              "       [10],\n",
              "       [41],\n",
              "       [60],\n",
              "       [60],\n",
              "       [41],\n",
              "       [59],\n",
              "       [56],\n",
              "       [53],\n",
              "       [77],\n",
              "       [68],\n",
              "       [58],\n",
              "       [52],\n",
              "       [67],\n",
              "       [ 8]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4G6k9aNBi2N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "d101c926-eca9-430d-fe5e-ffe72e8ed22c"
      },
      "source": [
        "# Reformat to not be a lists of lists\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "sampled_indices"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([15, 54, 38,  4, 50, 32, 30, 10, 59, 43, 85, 10, 50, 85, 10, 78, 15,\n",
              "       55, 30, 19, 38, 54, 70, 79, 55,  7, 56, 11, 37, 13, 22, 74, 77, 24,\n",
              "       15,  8, 53, 21, 40, 53, 41,  8, 61, 67, 67, 78, 69, 81, 13, 55, 68,\n",
              "       44, 85, 76, 20, 35, 77,  2, 80, 69, 42, 77, 75, 80, 50, 39,  4, 12,\n",
              "       52, 64, 82,  2, 58, 66, 39, 85, 84, 23, 10, 66, 21, 65, 36, 26, 85,\n",
              "       16, 10, 41, 60, 60, 41, 59, 56, 53, 77, 68, 58, 52, 67,  8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tNV7iNgCiHv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "87fb83f8-5ec4-4ab2-9363-4abbc406190f"
      },
      "source": [
        "print(\"Given the input seq: \\n\")\n",
        "print(\"\".join(ind_to_char[input_example_batch[0]]))\n",
        "print('\\n')\n",
        "print(\"Next Char Predictions: \\n\")\n",
        "print(\"\".join(ind_to_char[sampled_indices ]))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Given the input seq: \n",
            "\n",
            "rt at five feet, and bound round the ends, to prevent them\n",
            "splitting, with bands of copper; but he c\n",
            "\n",
            "\n",
            "Next Char Predictions: \n",
            "\n",
            "3`M%YGE.eR﻿.Y﻿.x3aE7M`pya*b/L1:tw?3,]9O]P,gmmxo‘1anS﻿v8Jw!zoQwuzYN%0[j’!dlN﻿”;.l9kKA﻿4.PffPeb]wnd[m,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izLtU8GBCgdK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "399d7751-22f7-44de-ed27-636109fbde54"
      },
      "source": [
        "epochs = 30\n",
        "model.fit(dataset,epochs=epochs)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "22/22 [==============================] - 136s 6s/step - loss: 4.2626\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 136s 6s/step - loss: 3.1719\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 137s 6s/step - loss: 2.9972\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 137s 6s/step - loss: 2.7668\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 136s 6s/step - loss: 2.5748\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 136s 6s/step - loss: 2.4735\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 136s 6s/step - loss: 2.4027\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 135s 6s/step - loss: 2.3440\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 135s 6s/step - loss: 2.2851\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 136s 6s/step - loss: 2.2307\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 137s 6s/step - loss: 2.1783\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 141s 6s/step - loss: 2.1226\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 138s 6s/step - loss: 2.0675\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 138s 6s/step - loss: 2.0117\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 137s 6s/step - loss: 1.9565\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 141s 6s/step - loss: 1.9043\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 140s 6s/step - loss: 1.8526\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 137s 6s/step - loss: 1.8049\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 138s 6s/step - loss: 1.7579\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 139s 6s/step - loss: 1.7128\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 138s 6s/step - loss: 1.6717\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 139s 6s/step - loss: 1.6326\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 139s 6s/step - loss: 1.5926\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 139s 6s/step - loss: 1.5567\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 136s 6s/step - loss: 1.5227\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 139s 6s/step - loss: 1.4894\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 144s 7s/step - loss: 1.4573\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 144s 7s/step - loss: 1.4253\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 141s 6s/step - loss: 1.3958\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 139s 6s/step - loss: 1.3673\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f534f203550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCvv56UEEf5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/Colab Notebooks/TextFiles/lionking_gen.h5') "
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azWnqGd2DW3p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "5f2ddb0f-5173-4f70-f3f4-beae4e3f7fb5"
      },
      "source": [
        "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
        "\n",
        "model.load_weights('/content/drive/My Drive/Colab Notebooks/TextFiles/lionking_gen.h5')\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 64)             5504      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (1, None, 1026)           3361176   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 86)             88322     \n",
            "=================================================================\n",
            "Total params: 3,455,002\n",
            "Trainable params: 3,455,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcHI4gKoFKXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_seed,gen_size=100,temp=1.0):\n",
        "  '''\n",
        "  model: Trained Model to Generate Text\n",
        "  start_seed: Intial Seed text in string form\n",
        "  gen_size: Number of characters to generate\n",
        "\n",
        "  Basic idea behind this function is to take in some seed text, format it so\n",
        "  that it is in the correct shape for our network, then loop the sequence as\n",
        "  we keep adding our own predicted characters. Similar to our work in the RNN\n",
        "  time series problems.\n",
        "  '''\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = gen_size\n",
        "\n",
        "  # Vecotrizing starting seed text\n",
        "  input_eval = [char_to_ind[s] for s in start_seed]\n",
        "\n",
        "  # Expand to match batch format shape\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty list to hold resulting generated text\n",
        "  text_generated = []\n",
        "\n",
        "  # Temperature effects randomness in our resulting text\n",
        "  # The term is derived from entropy/thermodynamics.\n",
        "  # The temperature is used to effect probability of next characters.\n",
        "  # Higher probability == lesss surprising/ more expected\n",
        "  # Lower temperature == more surprising / less expected\n",
        " \n",
        "  temperature = temp\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "\n",
        "      # Generate Predictions\n",
        "      predictions = model(input_eval)\n",
        "\n",
        "      # Remove the batch shape dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # Use a cateogircal disitribution to select the next character\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # Pass the predicted charracter for the next input\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      # Transform back to character letter\n",
        "      text_generated.append(ind_to_char[predicted_id])\n",
        "\n",
        "  return (start_seed + ''.join(text_generated))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0fl_Pwpn-lD",
        "colab_type": "text"
      },
      "source": [
        "**Model geenrated data based on the seed word**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_QVLwtrFNMp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "34035620-b117-4f51-d083-5ae52ffbd0ac"
      },
      "source": [
        "print(generate_text(model,\"Mowgli \",gen_size=1000))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mowgli that made to eath on the ground,\n",
            "and if no wor!\n",
            "     The moskets,” he said, for there who can to thucked atixald\n",
            "to meat Nag?”\n",
            "\n",
            "If ex the came aster that he had been heavy up the copyan in Indian from\n",
            "People.” Changs and out of the iss to sty of callata! It!\n",
            "     Averad a compenter day,\n",
            "where has noow his because. He was ear wairounds a\n",
            "           woll hinchess in the newty.”\n",
            "\n",
            "Litten Wolfs, and Kaa. “A rile tonk of the Humpriwht wird out on the carnaingles, hundred feolless out of his fifter slamons, under ast araverwamnout bride\n",
            "beastens ahe canching up nothing in the sefors without a\n",
            "neatly as his line and mulitut. He wishout broods, vercops and stunched See threw the singer” as hed and as\n",
            "of compliy\n",
            "noubred man nater. Har! All they can out of anything bag into mistul, and broke, how to huntre the prass at here as explain, and\n",
            "Rana.\n",
            "Lowg Wolves where he seascopthela. It’s hone.-\n",
            "“He had been saw ref on his shapped and diggling.\n",
            "\n",
            "“Thatkien carcoser and\n",
            "wampuntwer, shere Khan’s langee \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}